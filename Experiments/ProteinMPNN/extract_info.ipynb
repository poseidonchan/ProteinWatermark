{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae8255a-a7ea-43d2-b662-408ab659161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8133ad-553a-40c4-b0a8-75db69c3cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fa_file(file_path):\n",
    "    data = []  # List to store the parsed data\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('>'):\n",
    "                # Use regular expression to extract relevant information\n",
    "                info = re.search(r'^>([^,]+),.*sample=(\\d+),.*score=([^,]+),.*seq_recovery=([^,]+),.*pLDDT=(\\S+)', line)\n",
    "                if info:\n",
    "                    name_sample = f\"{info.group(1)}_{info.group(2)}\"\n",
    "                    score = info.group(3)\n",
    "                    seq_recovery = info.group(4)\n",
    "                    plddt = info.group(5)\n",
    "                    # Append the extracted information to the data list\n",
    "                    data.append({\n",
    "                        'sample': name_sample+\"_wm\" if \"wm\" in file_path else name_sample+\"_original\",\n",
    "                        'T': float(info.group(1)[2:]),\n",
    "                        'score': score,\n",
    "                        'seq_recovery': seq_recovery,\n",
    "                        'pLDDT': plddt,\n",
    "                        'type': \"wm\" if \"wm\" in file_path else \"original\"\n",
    "                    })\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba077cee-5a6c-4b46-ba6d-7c87ae0d8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(temperature):\n",
    "    original_path = \"./outputs/monomer_original_\"+str(temperature)+'/seqs/'\n",
    "    wm_path = './wm_outputs/monomer_wm_'+str(temperature)+'/seqs/'\n",
    "    filenames = os.listdir(original_path)\n",
    "    for filename in filenames:\n",
    "        if '.fa' in filename:\n",
    "            original_df = parse_fa_file(original_path+filename)\n",
    "            wm_df = parse_fa_file(wm_path+filename)\n",
    "            df = pd.concat([original_df,wm_df])\n",
    "            df.to_csv('./results/'+filename[:-3]+'_'+str(temperature)+'.csv')\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5fab42-85db-464f-b73c-de792afe372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_info(0.1)\n",
    "extract_info(0.3)\n",
    "extract_info(0.5)\n",
    "extract_info(0.7)\n",
    "extract_info(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f4974e-0cb7-4698-af28-15b91e776678",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir(\"./results\")\n",
    "file_names = [name for name in file_names if '.csv' in name ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60028136-7b60-4310-8297-cf6b1fd07850",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = set([name.split('_')[0] for name in file_names])\n",
    "\n",
    "# Directory where the files are located and where the new files will be saved\n",
    "dir_path = './results/'\n",
    "\n",
    "# Group files by prefix\n",
    "files_by_prefix = {prefix: [] for prefix in prefixes}\n",
    "\n",
    "for file_name in file_names:\n",
    "    prefix = file_name.split('_')[0]\n",
    "    files_by_prefix[prefix].append(file_name)\n",
    "\n",
    "# Concatenate and save files by prefix\n",
    "for prefix, files in files_by_prefix.items():\n",
    "    dfs = []  # To hold dataframes for concatenation\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(dir_path, file_name)\n",
    "        dfs.append(pd.read_csv(file_path,index_col=0))\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_file_name = f\"{prefix}.csv\"  # Updated to match your request\n",
    "    concatenated_df.to_csv(os.path.join(dir_path, combined_file_name), index=False)\n",
    "    \n",
    "    for file_name in files:\n",
    "        os.remove(os.path.join(dir_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d990787-63a3-4307-8dd5-d8213ab71403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
