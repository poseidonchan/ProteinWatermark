{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb390c14-0562-48c9-893a-203d792532e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union\n",
    "\n",
    "class AbstractWatermarkCode(ABC):\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_random(cls,\n",
    "                    rng: Union[np.random.Generator, list[np.random.Generator]],\n",
    "                    vocab_size: int):\n",
    "        pass\n",
    "\n",
    "class AbstractReweight(ABC):\n",
    "    watermark_code_type: type[AbstractWatermarkCode]\n",
    "\n",
    "    @abstractmethod\n",
    "    def reweight(self,\n",
    "                 code: AbstractWatermarkCode,\n",
    "                 p: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_la_score(self,\n",
    "                     code: AbstractWatermarkCode) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "def get_gumbel_variables(rng: np.random.Generator,\n",
    "                         vocab_size: int):\n",
    "    u = rng.random((vocab_size,))  # ~ Unifom(0, 1)\n",
    "    e = -np.log(u)  # ~ Exp(1)\n",
    "    g = -np.log(e)  # ~ Gumbel(0, 1)\n",
    "    return u, e, g\n",
    "\n",
    "\n",
    "class DeltaGumbel_WatermarkCode(AbstractWatermarkCode):\n",
    "    def __init__(self, g: np.ndarray):\n",
    "        self.g = g\n",
    "\n",
    "    @classmethod\n",
    "    def from_random(\n",
    "            cls,\n",
    "            rng: Union[np.random.Generator, list[np.random.Generator]],\n",
    "            vocab_size: int,\n",
    "    ):\n",
    "        if isinstance(rng, list):\n",
    "            batch_size = len(rng)\n",
    "            g = np.stack(\n",
    "                [get_gumbel_variables(rng[i], vocab_size)[2] for i in range(batch_size)]\n",
    "            )\n",
    "        else:\n",
    "            g = get_gumbel_variables(rng, vocab_size)[2]\n",
    "\n",
    "        return cls(g)\n",
    "\n",
    "\n",
    "class DeltaGumbel_Reweight(AbstractReweight):\n",
    "    watermark_code_type = DeltaGumbel_WatermarkCode\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DeltaGumbel_Reweight()\"\n",
    "\n",
    "    def reweight(\n",
    "            self, code: AbstractWatermarkCode, p_logits: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        assert isinstance(code, DeltaGumbel_WatermarkCode)\n",
    "\n",
    "        index = np.argmax(p_logits + code.g, axis=-1)\n",
    "\n",
    "        mask = np.arange(p_logits.shape[-1]) == index[..., None]\n",
    "\n",
    "        modified_logits = np.where(\n",
    "            mask,\n",
    "            np.full_like(p_logits, 0),\n",
    "            np.full_like(p_logits, float(\"-inf\")),\n",
    "        )\n",
    "        return modified_logits\n",
    "\n",
    "    def get_la_score(self, code):\n",
    "        \"\"\"likelihood agnostic score\"\"\"\n",
    "        return np.array(np.log(2)) - np.exp(-code.g)\n",
    "\n",
    "class WatermarkDetector:\n",
    "    def __init__(\n",
    "            self,\n",
    "            private_key: any,\n",
    "            reweight: AbstractReweight,\n",
    "            context_code_length: int,\n",
    "            vocab_size: int = 20,\n",
    "            ignore_history: bool = False\n",
    "    ):\n",
    "        self.private_key = private_key\n",
    "        self.cc_length = context_code_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.reweight = reweight\n",
    "        self.ignore_history = ignore_history\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def get_rng_seed(self, context_code: any) -> any:\n",
    "        if not self.ignore_history:\n",
    "            self.cc_history.add(context_code)\n",
    "        import hashlib\n",
    "\n",
    "        m = hashlib.sha256()\n",
    "        m.update(context_code)\n",
    "        m.update(self.private_key)\n",
    "        full_hash = m.digest()\n",
    "        seed = int.from_bytes(full_hash, \"big\") % (2 ** 32 - 1)\n",
    "        return seed\n",
    "\n",
    "    def _get_codes(self, context):\n",
    "        batch_size = len(context)\n",
    "\n",
    "        context_codes = [\n",
    "            context[i][-self.cc_length:].tobytes() for i in range(batch_size)\n",
    "        ]\n",
    "        # print(context[0][-self.cc_length:])\n",
    "        mask, seeds = zip(\n",
    "            *[\n",
    "                (context_code in self.cc_history, self.get_rng_seed(context_code))\n",
    "                for context_code in context_codes\n",
    "            ]\n",
    "        )\n",
    "        return mask, seeds\n",
    "\n",
    "    def detect(self,\n",
    "               input_ids: np.ndarray):\n",
    "        \"\"\"\n",
    "        :param input_ids: sequences after tokenization\n",
    "        :return: scores, a higher score means a seq is likely to be watermarked\n",
    "        \"\"\"\n",
    "\n",
    "        scores = []\n",
    "        for i in range(input_ids.shape[1]):\n",
    "            score = self.get_la_score(input_ids[:, :i], input_ids[:, i], self.vocab_size)\n",
    "            \n",
    "            ti = score-np.log(2)\n",
    "            scores.append(ti)\n",
    "        assert np.all(ti<=0), ti\n",
    "        tis = np.array(scores)\n",
    "        uis = np.exp(tis)\n",
    "        Ubar=np.mean(uis)\n",
    "        print(\"Ubar\", Ubar)\n",
    "\n",
    "        if np.mean(uis)==0:\n",
    "            final_score=0\n",
    "            final_p_value=1\n",
    "            return final_score, final_p_value\n",
    "        avgS = lambda Ubar, lamb: Ubar*lamb+np.log(lamb/np.expm1(lamb))\n",
    "        import scipy.optimize\n",
    "        sol=scipy.optimize.minimize(lambda l:-avgS(Ubar, l), 0.5,method='SLSQP', bounds=[(0,10)])\n",
    "        final_score=-sol.fun*input_ids.shape[1]\n",
    "        final_p_value = np.exp(-final_score)\n",
    "        return final_score, final_p_value\n",
    "        \n",
    "        A = np.mean(tis)\n",
    "        final_score = (-1-A-np.log(-A))*input_ids.shape[1]\n",
    "        final_p_value = np.exp(-final_score)\n",
    "\n",
    "        print(\"optimal score is\", final_score)\n",
    "        print(\"optimal p-value is\", final_p_value)\n",
    "        return final_score, final_p_value\n",
    "\n",
    "    def get_la_score(\n",
    "            self,\n",
    "            input_ids: np.ndarray,\n",
    "            labels: np.ndarray,\n",
    "            vocab_size: int,\n",
    "    ) -> np.ndarray:\n",
    "        assert \"get_la_score\" in dir(\n",
    "            self.reweight\n",
    "        ), \"Reweight does not support likelihood agnostic detection\"\n",
    "        mask, seeds = self._get_codes(input_ids)\n",
    "        rng = [\n",
    "            np.random.default_rng(seed) for seed in seeds\n",
    "        ]\n",
    "        \n",
    "        mask = np.array(mask)\n",
    "        watermark_code = self.reweight.watermark_code_type.from_random(rng, vocab_size)\n",
    "        all_scores = self.reweight.get_la_score(watermark_code)\n",
    "        scores = all_scores[np.arange(all_scores.shape[0]), labels]\n",
    "        \n",
    "        scores = np.logical_not(mask) * scores\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0e0e24d-8053-407a-8ec7-63407679246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = 'ARNDCQEGHILKMFPSTWYVX-'\n",
    "# Create a dictionary mapping each amino acid to its index\n",
    "aa_to_index = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "class AminoAcidTokenizer:\n",
    "    def __init__(self, aa_to_index):\n",
    "        self.aa_to_index = aa_to_index\n",
    "        self.index_to_aa = {idx: aa for aa, idx in aa_to_index.items()}\n",
    "        \n",
    "    def encode(self, sequence):\n",
    "        # Encode a sequence of amino acids to indices\n",
    "        return np.array([self.aa_to_index.get(aa, self.aa_to_index.get('X')) for aa in sequence]).reshape(1,-1)\n",
    "        \n",
    "    def decode(self, indices):\n",
    "        # Decode a list of indices back into an amino acid sequence\n",
    "        return ''.join(self.index_to_aa.get(idx, 'X') for idx in indices)\n",
    "tokenizer = AminoAcidTokenizer(aa_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41ed66f8-a86d-4c9a-8952-118c48d2eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubar 0.4923574826583142\n",
      "(array([1.36656653e-15]), array([1.]))\n"
     ]
    }
   ],
   "source": [
    "# sequence = \"STLETTPKGSEGVNVTKLECSLPSGVKTAQWSGPRSAPNGVFVGSDASISFDPGKTVTLMSAASGTGYKCLAMLKIQAYFNETADLPCQFANSQNQSLSELVVFWQDQENLVLNEVYLGKEKFDSVHSKYMGRTSFDSDSWTLRLHNLQIKDKGLYQCIIHHKKPTGMIRIHQMNSELSVLA\"\n",
    "# sequence = \"KIQAYFNETADLPCQFANSQNQSLSELVVFWQDQENLVLNEVYLGSEKFDSVHSKYMGRTSFDSDSWTLRLHNLQIKDKGLYQCIIHHKKPTGMIRIHQMNSELSVLA\"\n",
    "# sequence = \"STLEPTRKGSEGVNVTKLECSLPSGVKSAQWSGPGSGPQGVFVIGDAXISSDPGKTVTLKSAASGTGYKCLAML\"\n",
    "sequence = \"NMSKEEIKEIMEKIDKIEKELEKISKGLTKEEREELLERIRKEINELFEISGKDFLPKEELEKLQKTLEELREGRNPDEKIEKFLEVLKKIRERLERALN\"\n",
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=21)\n",
    "\n",
    "print(detector.detect(tokenizer.encode(sequence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254d80c1-1b88-459e-9c71-bc66b85d1e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/js/g7pncpj135j12v52t38tgclh0000gn/T/ipykernel_56161/1179788289.py:151: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avgS = lambda Ubar, lamb: Ubar*lamb+np.log(lamb/np.expm1(lamb))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sample  iteration   entropy   pLDDT     watermark\n",
      "0      000000          1  2.722656  0.2717  2.080855e-04\n",
      "1      000000          2  2.740234  0.3022  6.619150e-07\n",
      "2      000000          3  2.490234  0.4558  5.477644e-05\n",
      "3      000000          4  2.410156  0.4575  3.575793e-03\n",
      "4      000000          5  2.314453  0.4785 -7.802704e-04\n",
      "...       ...        ...       ...     ...           ...\n",
      "12495  000499         21  0.508301  0.9092 -4.802248e-04\n",
      "12496  000499         22  0.834961  0.9062 -4.171029e-03\n",
      "12497  000499         23  0.807617  0.9058 -4.171029e-03\n",
      "12498  000499         24  1.127930  0.9014 -4.171029e-03\n",
      "12499  000499         25  0.757812  0.9043 -4.171029e-03\n",
      "\n",
      "[12500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sample_re = re.compile(r'Generating sample (\\d+) \\.\\.\\.')\n",
    "entropy_re = re.compile(r'WaterMarked Entropy: ([\\d.]+)')\n",
    "timestep_re = re.compile(r'TIMESTEP \\[(\\d+)/(\\d+)\\].*current PLDDT: ([\\d.]+)')\n",
    "\n",
    "# List to hold extracted data\n",
    "extracted_data = []\n",
    "input_file_path = './secondary_structure_wm.log'\n",
    "output_file_path = './secondary_structure_wm.csv'\n",
    "\n",
    "with open(input_file_path, 'r') as file:\n",
    "    sample_number = None\n",
    "    entropy = None\n",
    "    sequence = None\n",
    "    expect_sequence = False\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if not line:  # Skip empty lines\n",
    "            continue\n",
    "        # Match each line against the regular expressions\n",
    "        sample_match = sample_re.search(line)\n",
    "        entropy_match = entropy_re.search(line)\n",
    "        timestep_match = timestep_re.search(line)\n",
    "        \n",
    "        detector = WatermarkDetector(b\"privatee key\",\n",
    "                                     DeltaGumbel_Reweight(),\n",
    "                                     context_code_length=5,\n",
    "                                     vocab_size=21)\n",
    "        \n",
    "        if sample_match:\n",
    "            sample_number = sample_match.group(1)\n",
    "        elif entropy_match:\n",
    "            entropy = entropy_match.group(1)\n",
    "            expect_sequence = True\n",
    "        elif timestep_match:\n",
    "            current_iteration, total_iterations, current_plddt = timestep_match.groups()\n",
    "            modified_iteration = int(total_iterations) + 1 - int(current_iteration)\n",
    "            extracted_data.append({\n",
    "                'sample': sample_number,\n",
    "                'iteration': int(modified_iteration),\n",
    "                'entropy': float(entropy),\n",
    "                'pLDDT': float(current_plddt),\n",
    "                'watermark': ((detector.detect(tokenizer.encode(sequence), method='optimized')[0])/len(sequence))[0]\n",
    "            })\n",
    "            expect_sequence = False\n",
    "        elif expect_sequence:\n",
    "            sequence = line\n",
    "            expect_sequence = False\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(extracted_data)\n",
    "print(df)\n",
    "# df.to_csv(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcc403bc-3a92-4d42-9858-98efb2dd3a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0269ab97-e7bd-4986-8f83-62ed3f9794a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
