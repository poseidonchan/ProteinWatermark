{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f206ac3-b0fe-485f-800f-fc653b169125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fca42b-02ba-4814-915a-e3c13dcb312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import numpy as np\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class AbstractWatermarkCode(ABC):\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_random(cls,\n",
    "                    rng: Union[np.random.Generator, list[np.random.Generator]],\n",
    "                    vocab_size: int):\n",
    "        pass\n",
    "\n",
    "\n",
    "class AbstractReweight(ABC):\n",
    "    watermark_code_type: type[AbstractWatermarkCode]\n",
    "\n",
    "    @abstractmethod\n",
    "    def reweight(self,\n",
    "                 code: AbstractWatermarkCode,\n",
    "                 p: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_gumbel_variables(rng: np.random.Generator,\n",
    "                         vocab_size: int):\n",
    "    u = rng.random((vocab_size,))  # ~ Unifom(0, 1)\n",
    "    e = -np.log(u)  # ~ Exp(1)\n",
    "    g = -np.log(e)  # ~ Gumbel(0, 1)\n",
    "    return u, e, g\n",
    "\n",
    "\n",
    "class DeltaGumbel_WatermarkCode(AbstractWatermarkCode):\n",
    "    def __init__(self, g: np.ndarray):\n",
    "        self.g = g\n",
    "\n",
    "    @classmethod\n",
    "    def from_random(\n",
    "        cls,\n",
    "        rng: Union[np.random.Generator, list[np.random.Generator]],\n",
    "        vocab_size: int,\n",
    "    ):\n",
    "        if isinstance(rng, list):\n",
    "            batch_size = len(rng)\n",
    "            g = np.stack(\n",
    "                [get_gumbel_variables(rng[i], vocab_size)[2] for i in range(batch_size)]\n",
    "            )\n",
    "        else:\n",
    "            g = get_gumbel_variables(rng, vocab_size)[2]\n",
    "\n",
    "        return cls(g)\n",
    "\n",
    "\n",
    "class DeltaGumbel_Reweight(AbstractReweight):\n",
    "    watermark_code_type = DeltaGumbel_WatermarkCode\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DeltaGumbel_Reweight()\"\n",
    "\n",
    "    def reweight(\n",
    "        self, code: AbstractWatermarkCode, p_logits: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "\n",
    "        assert isinstance(code, DeltaGumbel_WatermarkCode)\n",
    "\n",
    "        index = np.argmax(p_logits + code.g, axis=-1)\n",
    "\n",
    "        mask = np.arange(p_logits.shape[-1]) == index[..., None]\n",
    "\n",
    "        modified_logits = np.where(\n",
    "            mask,\n",
    "            np.full_like(p_logits, 0),\n",
    "            np.full_like(p_logits, float(\"-inf\")),\n",
    "        )\n",
    "        return modified_logits\n",
    "\n",
    "    def get_la_score(self, code):\n",
    "        \"\"\"likelihood agnostic score\"\"\"\n",
    "        return np.array(np.log(2)) - np.exp(-code.g)\n",
    "\n",
    "\n",
    "class WatermarkProcessor:\n",
    "    def __init__(\n",
    "            self,\n",
    "            private_key: any,\n",
    "            reweight: AbstractReweight,\n",
    "            context_code_length: int,\n",
    "            ignore_history=False,\n",
    "    ):\n",
    "\n",
    "        self.private_key = private_key\n",
    "        self.reweight = reweight\n",
    "        self.cc_length = context_code_length\n",
    "        self.ignore_history = ignore_history\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def get_rng_seed(self, context_code: any) -> any:\n",
    "        if not self.ignore_history:\n",
    "            self.cc_history.add(context_code)\n",
    "        import hashlib\n",
    "\n",
    "        m = hashlib.sha256()\n",
    "        m.update(context_code)\n",
    "        m.update(self.private_key)\n",
    "        full_hash = m.digest()\n",
    "        seed = int.from_bytes(full_hash, \"big\") % (2 ** 32 - 1)\n",
    "        return seed\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def _get_codes(self, context, current_pos):\n",
    "        batch_size = len(context)\n",
    "\n",
    "        if current_pos == 0:\n",
    "            context_codes = [\n",
    "                context[i][-self.cc_length:].tobytes() for i in range(batch_size)\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            cc_pos = current_pos - self.cc_length\n",
    "            \n",
    "            if cc_pos < 0:\n",
    "                cc_pos = 0\n",
    "            else:\n",
    "                cc_pos = cc_pos\n",
    "            \n",
    "            context_codes = [\n",
    "                context[i][cc_pos:current_pos][~np.isnan(context[i][cc_pos:current_pos])].tobytes() for i in range(batch_size)\n",
    "            ]\n",
    "\n",
    "        mask, seeds = zip(\n",
    "            *[\n",
    "                (context_code in self.cc_history, self.get_rng_seed(context_code))\n",
    "                for context_code in context_codes\n",
    "            ]\n",
    "        )\n",
    "        return mask, seeds\n",
    "\n",
    "    def __call__(self, \n",
    "                 mode: str = 'normal',\n",
    "                 context: np.ndarray = None,\n",
    "                 logits: np.ndarray = None,\n",
    "                 current_pos: int = None):\n",
    "\n",
    "        if mode == 'normal':\n",
    "            current_pos = 0\n",
    "        elif mode == 'order_agnoistic':\n",
    "            current_pos = current_pos\n",
    "        else:\n",
    "            raise NotImplementedError('Current watermark processor does not support this mode')\n",
    "\n",
    "        mask, seeds = self._get_codes(context, current_pos=current_pos)\n",
    "\n",
    "        rng = [\n",
    "            np.random.default_rng(seed) for seed in seeds\n",
    "        ]\n",
    "\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        watermark_code = self.reweight.watermark_code_type.from_random(\n",
    "            rng, logits.shape[1]\n",
    "        )\n",
    "\n",
    "        reweighted_logits = self.reweight.reweight(watermark_code, logits)\n",
    "\n",
    "        if self.ignore_history:\n",
    "            return reweighted_logits\n",
    "        else:\n",
    "            return np.where(mask[:, None], logits, reweighted_logits)\n",
    "\n",
    "\n",
    "class WatermarkDetector:\n",
    "    def __init__(\n",
    "            self,\n",
    "            private_key: any,\n",
    "            reweight: AbstractReweight,\n",
    "            context_code_length: int,\n",
    "            vocab_size: int = 20,\n",
    "            ignore_history: bool = False\n",
    "    ):\n",
    "        self.private_key = private_key\n",
    "        self.cc_length = context_code_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.reweight = reweight\n",
    "        self.ignore_history = ignore_history\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def get_rng_seed(self, context_code: any) -> any:\n",
    "        if not self.ignore_history:\n",
    "            self.cc_history.add(context_code)\n",
    "        import hashlib\n",
    "\n",
    "        m = hashlib.sha256()\n",
    "        m.update(context_code)\n",
    "        m.update(self.private_key)\n",
    "        full_hash = m.digest()\n",
    "        seed = int.from_bytes(full_hash, \"big\") % (2 ** 32 - 1)\n",
    "        return seed\n",
    "\n",
    "    def _get_codes(self, context):\n",
    "        batch_size = len(context)\n",
    "\n",
    "        context_codes = [\n",
    "            context[i][-self.cc_length:].tobytes() for i in range(batch_size)\n",
    "        ]\n",
    "\n",
    "        mask, seeds = zip(\n",
    "            *[\n",
    "                (context_code in self.cc_history, self.get_rng_seed(context_code))\n",
    "                for context_code in context_codes\n",
    "            ]\n",
    "        )\n",
    "        return mask, seeds\n",
    "\n",
    "    def detect(self,\n",
    "               input_ids: np.ndarray):\n",
    "        \"\"\"\n",
    "        :param input_ids: sequences after tokenization\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = []\n",
    "        for i in range(input_ids.shape[1]):\n",
    "\n",
    "            score = self.get_la_score(input_ids[:,:i], input_ids[:,i], self.vocab_size)\n",
    "            scores.append(score)\n",
    "            \n",
    "        scores = np.array(scores) \n",
    "        return np.sum(scores, axis=0)\n",
    "\n",
    "    def get_la_score(\n",
    "        self,\n",
    "        input_ids: np.ndarray,\n",
    "        labels: np.ndarray,\n",
    "        vocab_size: int,\n",
    "    ) -> np.ndarray:\n",
    "        assert \"get_la_score\" in dir(\n",
    "            self.reweight\n",
    "        ), \"Reweight does not support likelihood agnostic detection\"\n",
    "        mask, seeds = self._get_codes(input_ids)\n",
    "        rng = [\n",
    "            np.random.default_rng(seed) for seed in seeds\n",
    "        ]\n",
    "        mask = np.array(mask)\n",
    "        watermark_code = self.reweight.watermark_code_type.from_random(rng, vocab_size)\n",
    "        all_scores = self.reweight.get_la_score(watermark_code)\n",
    "        scores = all_scores[np.arange(all_scores.shape[0]), labels]\n",
    "        scores = np.logical_not(mask) * scores\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d235493-576d-4823-aa9f-b8777ee847f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = np.array([[ 4, np.nan, np.nan, 15, 20, 18],\n",
    "                     [ 5, np.nan, np.nan,  2,  0, 15],\n",
    "                     [ 5, np.nan, np.nan, 21, 10, 17],\n",
    "                     [ 6, np.nan, np.nan, 10, 15, 8],\n",
    "                     [ 6, np.nan, np.nan, 9, 25, 9]])\n",
    "logits = np.random.random((5, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fe2d96-62b2-4477-87cd-ca86144f6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_processor = WatermarkProcessor(private_key=b'private',\n",
    "                                         reweight=DeltaGumbel_Reweight(),\n",
    "                                         context_code_length=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d132d70c-bffa-4c45-be85-54ea8318db69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27345002, 0.46073045, 0.96927645, 0.75624814, 0.69989047,\n",
       "        0.50814657, 0.43346905, 0.74601261, 0.96998015, 0.37814076,\n",
       "        0.39418337, 0.58310508, 0.20646198, 0.64546119, 0.24977696,\n",
       "        0.79664081, 0.18938096, 0.47139425, 0.0873729 , 0.28474509],\n",
       "       [0.32283926, 0.08903497, 0.21233506, 0.10430039, 0.3206153 ,\n",
       "        0.17804705, 0.04651974, 0.53754152, 0.10692629, 0.80250703,\n",
       "        0.55071335, 0.25694895, 0.93563718, 0.49728107, 0.65539614,\n",
       "        0.53114406, 0.51073647, 0.95689727, 0.95227567, 0.62795639],\n",
       "       [0.13787495, 0.03095741, 0.10545715, 0.56647594, 0.74173664,\n",
       "        0.22204499, 0.1169336 , 0.9389509 , 0.87800631, 0.11468302,\n",
       "        0.20173521, 0.49373343, 0.28704077, 0.73549827, 0.86923247,\n",
       "        0.02852061, 0.45394992, 0.2598513 , 0.35724781, 0.03543314],\n",
       "       [0.71464493, 0.13757047, 0.4150354 , 0.42264515, 0.06106554,\n",
       "        0.98146016, 0.36787342, 0.03697618, 0.2226742 , 0.38606002,\n",
       "        0.88420054, 0.43256975, 0.43924154, 0.89863907, 0.69898482,\n",
       "        0.63931228, 0.90456482, 0.82437165, 0.03946043, 0.5239519 ],\n",
       "       [0.89280055, 0.56346356, 0.97110213, 0.45405194, 0.90585511,\n",
       "        0.54289677, 0.2105664 , 0.27127285, 0.91593092, 0.22251806,\n",
       "        0.5202445 , 0.38030895, 0.89527122, 0.17119083, 0.7344982 ,\n",
       "        0.19275765, 0.56105371, 0.95501649, 0.64232095, 0.72049109]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11812db0-6314-4a1b-a421-d463058d1240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf, 0.        ,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf],\n",
       "       [      -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf, 0.        ,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf],\n",
       "       [0.13787495, 0.03095741, 0.10545715, 0.56647594, 0.74173664,\n",
       "        0.22204499, 0.1169336 , 0.9389509 , 0.87800631, 0.11468302,\n",
       "        0.20173521, 0.49373343, 0.28704077, 0.73549827, 0.86923247,\n",
       "        0.02852061, 0.45394992, 0.2598513 , 0.35724781, 0.03543314],\n",
       "       [      -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf, 0.        ,       -inf,       -inf,       -inf],\n",
       "       [0.89280055, 0.56346356, 0.97110213, 0.45405194, 0.90585511,\n",
       "        0.54289677, 0.2105664 , 0.27127285, 0.91593092, 0.22251806,\n",
       "        0.5202445 , 0.38030895, 0.89527122, 0.17119083, 0.7344982 ,\n",
       "        0.19275765, 0.56105371, 0.95501649, 0.64232095, 0.72049109]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watermark_processor('order_agnoistic', input_id, logits, 1) # add watermark, two samples are not added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f762dd3b-ab30-476e-a9d5-b2a3e6a846aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27345002, 0.46073045, 0.96927645, 0.75624814, 0.69989047,\n",
       "        0.50814657, 0.43346905, 0.74601261, 0.96998015, 0.37814076,\n",
       "        0.39418337, 0.58310508, 0.20646198, 0.64546119, 0.24977696,\n",
       "        0.79664081, 0.18938096, 0.47139425, 0.0873729 , 0.28474509],\n",
       "       [0.32283926, 0.08903497, 0.21233506, 0.10430039, 0.3206153 ,\n",
       "        0.17804705, 0.04651974, 0.53754152, 0.10692629, 0.80250703,\n",
       "        0.55071335, 0.25694895, 0.93563718, 0.49728107, 0.65539614,\n",
       "        0.53114406, 0.51073647, 0.95689727, 0.95227567, 0.62795639],\n",
       "       [0.13787495, 0.03095741, 0.10545715, 0.56647594, 0.74173664,\n",
       "        0.22204499, 0.1169336 , 0.9389509 , 0.87800631, 0.11468302,\n",
       "        0.20173521, 0.49373343, 0.28704077, 0.73549827, 0.86923247,\n",
       "        0.02852061, 0.45394992, 0.2598513 , 0.35724781, 0.03543314],\n",
       "       [0.71464493, 0.13757047, 0.4150354 , 0.42264515, 0.06106554,\n",
       "        0.98146016, 0.36787342, 0.03697618, 0.2226742 , 0.38606002,\n",
       "        0.88420054, 0.43256975, 0.43924154, 0.89863907, 0.69898482,\n",
       "        0.63931228, 0.90456482, 0.82437165, 0.03946043, 0.5239519 ],\n",
       "       [0.89280055, 0.56346356, 0.97110213, 0.45405194, 0.90585511,\n",
       "        0.54289677, 0.2105664 , 0.27127285, 0.91593092, 0.22251806,\n",
       "        0.5202445 , 0.38030895, 0.89527122, 0.17119083, 0.7344982 ,\n",
       "        0.19275765, 0.56105371, 0.95501649, 0.64232095, 0.72049109]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watermark_processor('order_agnoistic', input_id, logits, 2) # no watermark should be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e54c83-a703-4d55-837e-2220d864d289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27345002, 0.46073045, 0.96927645, 0.75624814, 0.69989047,\n",
       "        0.50814657, 0.43346905, 0.74601261, 0.96998015, 0.37814076,\n",
       "        0.39418337, 0.58310508, 0.20646198, 0.64546119, 0.24977696,\n",
       "        0.79664081, 0.18938096, 0.47139425, 0.0873729 , 0.28474509],\n",
       "       [0.32283926, 0.08903497, 0.21233506, 0.10430039, 0.3206153 ,\n",
       "        0.17804705, 0.04651974, 0.53754152, 0.10692629, 0.80250703,\n",
       "        0.55071335, 0.25694895, 0.93563718, 0.49728107, 0.65539614,\n",
       "        0.53114406, 0.51073647, 0.95689727, 0.95227567, 0.62795639],\n",
       "       [0.13787495, 0.03095741, 0.10545715, 0.56647594, 0.74173664,\n",
       "        0.22204499, 0.1169336 , 0.9389509 , 0.87800631, 0.11468302,\n",
       "        0.20173521, 0.49373343, 0.28704077, 0.73549827, 0.86923247,\n",
       "        0.02852061, 0.45394992, 0.2598513 , 0.35724781, 0.03543314],\n",
       "       [0.71464493, 0.13757047, 0.4150354 , 0.42264515, 0.06106554,\n",
       "        0.98146016, 0.36787342, 0.03697618, 0.2226742 , 0.38606002,\n",
       "        0.88420054, 0.43256975, 0.43924154, 0.89863907, 0.69898482,\n",
       "        0.63931228, 0.90456482, 0.82437165, 0.03946043, 0.5239519 ],\n",
       "       [0.89280055, 0.56346356, 0.97110213, 0.45405194, 0.90585511,\n",
       "        0.54289677, 0.2105664 , 0.27127285, 0.91593092, 0.22251806,\n",
       "        0.5202445 , 0.38030895, 0.89527122, 0.17119083, 0.7344982 ,\n",
       "        0.19275765, 0.56105371, 0.95501649, 0.64232095, 0.72049109]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watermark_processor('order_agnoistic', input_id, logits, 3) # no watermark should be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e420e-7d59-41e8-b47b-4f6265435290",
   "metadata": {},
   "source": [
    "### Naive tokenizer construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2512b05-9df9-495b-bc70-77216a90060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 17, 2, 0, 2, 16, 13, 8, 0, 9, 2, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWYX'  # List of amino acids\n",
    "# Create a dictionary mapping each amino acid to its index\n",
    "aa_to_index = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "class AminoAcidTokenizer:\n",
    "    def __init__(self, aa_to_index):\n",
    "        self.aa_to_index = aa_to_index\n",
    "        self.index_to_aa = {idx: aa for aa, idx in aa_to_index.items()}\n",
    "        \n",
    "    def encode(self, sequence):\n",
    "        # Encode a sequence of amino acids to indices\n",
    "        return [self.aa_to_index.get(aa, self.aa_to_index.get('X')) for aa in sequence]\n",
    "        \n",
    "    def decode(self, indices):\n",
    "        # Decode a list of indices back into an amino acid sequence\n",
    "        return ''.join(self.index_to_aa.get(idx, 'X') for idx in indices)\n",
    "tokenizer = AminoAcidTokenizer(aa_to_index)\n",
    "encoded_input = tokenizer.encode(\"MVDADTQKALDFI\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b42716-8fdf-4733-9520-56e36117ae3a",
   "metadata": {},
   "source": [
    "### Read Tokenizer File to construct original tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720f1f0f-f975-4c60-8274-8e6ff13e0286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cys/miniconda3/envs/BSW/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 11, 19, 19, 25, 25, 21, 15, 8, 9, 13, 21, 11, 21, 11, 13, 21, 25, 9, 10, 8, 5, 11, 11, 25, 25, 21, 15, 15, 23, 9, 21, 15, 9, 21, 5, 5, 5, 9, 19, 5, 15, 21, 25, 19, 15, 5, 15, 21, 5, 22, 21, 11, 21, 21, 9, 13, 21, 15, 20, 5, 8, 21, 25, 11, 19, 15, 21, 5, 15, 23, 9, 21, 15, 25, 9, 15, 22, 5, 19, 9, 21, 25, 5, 25, 21, 15, 5, 19, 11, 8, 9, 11, 11, 25, 9, 25, 15, 19, 21, 25, 9, 5, 15, 25, 15, 5, 25, 15, 8, 19, 8, 21, 9, 25, 9, 25, 5, 25, 15, 5, 11, 14, 5, 21, 22, 9, 13, 22, 15, 25, 5, 11, 21, 21, 15, 15, 9, 21, 21, 25, 5, 22, 9, 19, 15, 19, 5, 5, 5, 25, 15, 5, 10, 15, 11, 9, 5, 15, 21, 9, 9, 15, 15, 25, 19, 15, 8, 5, 15, 21, 11, 15, 5, 21, 21, 25, 5, 9, 11, 11, 11, 5, 9, 15, 21, 15, 23, 15, 15, 22, 21, 5, 21, 5, 9, 25, 25, 15]\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"./tokenizer.json\")\n",
    "encoded_input = tokenizer.encode(\"GGPPVVRLDEIRGRGIRVEFDAGGVVRLLTERLERAAAEPALRVPLALRASRGRREIRLQADRVGPLRALTERLVELSAPERVAVRLAPGDEGGVEVLPRVEALVLAVLDPDREVEVAVLAGKARSEISLVAGRRLLERRVASEPLPAAAVLAFLGEALREELLVPLDALRGLARRVAEGGGAELRLTLLSRARAEVVL\")\n",
    "# encoded_input = tokenizer.encode(\"2GGPPVVRLD\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e08e8ae8-5df8-443c-be3d-ae24bc87fa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c334378-0f72-44d8-aba5-a6e5986f3db0",
   "metadata": {},
   "source": [
    "### Detection with Private Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ce280dc-fa05-4fa9-95a9-56473b9de64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a98a60e-98fc-426b-bd7c-6d289cabe5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = np.array(encoded_input).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ab91c4b-6a69-4b10-b40d-3e53c8dc8bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63.62662829])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.detect(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85acab9f-754e-4ded-8f14-5f9e7599f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.log(2) - (1/30) # theoretically maximum score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff807947-4db8-434d-b253-9321992591fa",
   "metadata": {},
   "source": [
    "### Without Correct Key, Score Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9547176-1b18-4028-8b3d-bd415e38efb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-69.73725497])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = WatermarkDetector(b\"private keey\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)\n",
    "detector.detect(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f2b49-f35e-42eb-b818-e71884eb90f8",
   "metadata": {},
   "source": [
    "### Watermark is Relatively Robust to Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84847677-ffc8-4cbd-9d44-96bd790836d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.63254586])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"./tokenizer.json\")\n",
    "# select the head of the protein\n",
    "encoded_input = tokenizer.encode(\"GGPPVVRLDEIRGRGIRVEFDAGGVVRLLTERLERAAAEPALRVPLAL\")\n",
    "input_ids = np.array(encoded_input).reshape(1,-1)\n",
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)\n",
    "detector.detect(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66d383a8-d142-487f-b6a1-2ab4461c12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 11, 19, 19, 25, 25, 21, 15, 8, 9, 13, 21, 11, 21, 11, 13, 21, 25, 9, 10, 8, 11, 11, 11, 25, 25, 21, 15, 15, 23, 9, 21, 15, 9, 21, 11, 11, 11, 9, 19, 11, 15, 21, 25, 19, 15, 11, 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.64354916])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify the sequence by changing A to G\n",
    "encoded_input = tokenizer.encode(\"GGPPVVRLDEIRGRGIRVEFDGGGVVRLLTERLERGGGEPGLRVPLGL\")\n",
    "print(encoded_input)\n",
    "input_ids = np.array(encoded_input).reshape(1,-1)\n",
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)\n",
    "detector.detect(input_ids) # we still have some watermark in it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473e53e-a7f1-4270-8f13-666e9a06b44e",
   "metadata": {},
   "source": [
    "### Detect multiple sequences at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffa05aa5-e3f5-4fab-9a95-71ef331720c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.64354916, 0.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)\n",
    "detector.detect(np.concatenate([input_ids, input_ids])) # we still have some watermark in it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e045b4-5470-4f03-901b-fd2022ba7c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
