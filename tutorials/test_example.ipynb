{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f206ac3-b0fe-485f-800f-fc653b169125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fca42b-02ba-4814-915a-e3c13dcb312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import numpy as np\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class AbstractWatermarkCode(ABC):\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_random(cls,\n",
    "                    rng: Union[np.random.Generator, list[np.random.Generator]],\n",
    "                    vocab_size: int):\n",
    "        pass\n",
    "\n",
    "\n",
    "class AbstractReweight(ABC):\n",
    "    watermark_code_type: type[AbstractWatermarkCode]\n",
    "\n",
    "    @abstractmethod\n",
    "    def reweight(self,\n",
    "                 code: AbstractWatermarkCode,\n",
    "                 p: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_gumbel_variables(rng: np.random.Generator,\n",
    "                         vocab_size: int):\n",
    "    u = rng.random((vocab_size,))  # ~ Unifom(0, 1)\n",
    "    e = -np.log(u)  # ~ Exp(1)\n",
    "    g = -np.log(e)  # ~ Gumbel(0, 1)\n",
    "    return u, e, g\n",
    "\n",
    "\n",
    "class DeltaGumbel_WatermarkCode(AbstractWatermarkCode):\n",
    "    def __init__(self, g: np.ndarray):\n",
    "        self.g = g\n",
    "\n",
    "    @classmethod\n",
    "    def from_random(\n",
    "        cls,\n",
    "        rng: Union[np.random.Generator, list[np.random.Generator]],\n",
    "        vocab_size: int,\n",
    "    ):\n",
    "        if isinstance(rng, list):\n",
    "            batch_size = len(rng)\n",
    "            g = np.stack(\n",
    "                [get_gumbel_variables(rng[i], vocab_size)[2] for i in range(batch_size)]\n",
    "            )\n",
    "        else:\n",
    "            g = get_gumbel_variables(rng, vocab_size)[2]\n",
    "\n",
    "        return cls(g)\n",
    "\n",
    "\n",
    "class DeltaGumbel_Reweight(AbstractReweight):\n",
    "    watermark_code_type = DeltaGumbel_WatermarkCode\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DeltaGumbel_Reweight()\"\n",
    "\n",
    "    def reweight(\n",
    "        self, code: AbstractWatermarkCode, p_logits: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "\n",
    "        assert isinstance(code, DeltaGumbel_WatermarkCode)\n",
    "\n",
    "        index = np.argmax(p_logits + code.g, axis=-1)\n",
    "\n",
    "        mask = np.arange(p_logits.shape[-1]) == index[..., None]\n",
    "\n",
    "        modified_logits = np.where(\n",
    "            mask,\n",
    "            np.full_like(p_logits, 0),\n",
    "            np.full_like(p_logits, float(\"-inf\")),\n",
    "        )\n",
    "        return modified_logits\n",
    "\n",
    "    def get_la_score(self, code):\n",
    "        \"\"\"likelihood agnostic score\"\"\"\n",
    "        return np.array(np.log(2)) - np.exp(-code.g)\n",
    "\n",
    "\n",
    "class WatermarkProcessor:\n",
    "    def __init__(\n",
    "            self,\n",
    "            private_key: any,\n",
    "            reweight: AbstractReweight,\n",
    "            context_code_length: int,\n",
    "            ignore_history=False,\n",
    "    ):\n",
    "\n",
    "        self.private_key = private_key\n",
    "        self.reweight = reweight\n",
    "        self.cc_length = context_code_length\n",
    "        self.ignore_history = ignore_history\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def get_rng_seed(self, context_code: any) -> any:\n",
    "        if not self.ignore_history:\n",
    "            self.cc_history.add(context_code)\n",
    "        import hashlib\n",
    "\n",
    "        m = hashlib.sha256()\n",
    "        m.update(context_code)\n",
    "        m.update(self.private_key)\n",
    "        full_hash = m.digest()\n",
    "        seed = int.from_bytes(full_hash, \"big\") % (2 ** 32 - 1)\n",
    "        return seed\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def _get_codes(self, context, current_pos):\n",
    "        batch_size = len(context)\n",
    "\n",
    "        if current_pos == 0:\n",
    "            context_codes = [\n",
    "                context[i][-self.cc_length:].tobytes() for i in range(batch_size)\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            cc_pos = current_pos - self.cc_length\n",
    "            \n",
    "            if cc_pos < 0:\n",
    "                cc_pos = 0\n",
    "            else:\n",
    "                cc_pos = cc_pos\n",
    "            \n",
    "            context_codes = [\n",
    "                context[i][cc_pos:current_pos][~np.isnan(context[i][cc_pos:current_pos])].tobytes() for i in range(batch_size)\n",
    "            ]\n",
    "\n",
    "        mask, seeds = zip(\n",
    "            *[\n",
    "                (context_code in self.cc_history, self.get_rng_seed(context_code))\n",
    "                for context_code in context_codes\n",
    "            ]\n",
    "        )\n",
    "        return mask, seeds\n",
    "\n",
    "    def __call__(self, \n",
    "                 mode: str = 'normal',\n",
    "                 context: np.ndarray = None,\n",
    "                 logits: np.ndarray = None,\n",
    "                 current_pos: int = None):\n",
    "\n",
    "        if mode == 'normal':\n",
    "            current_pos = 0\n",
    "        elif mode == 'order_agnoistic':\n",
    "            current_pos = current_pos\n",
    "        else:\n",
    "            raise NotImplementedError('Current watermark processor does not support this mode')\n",
    "\n",
    "        mask, seeds = self._get_codes(context, current_pos=current_pos)\n",
    "\n",
    "        rng = [\n",
    "            np.random.default_rng(seed) for seed in seeds\n",
    "        ]\n",
    "\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        watermark_code = self.reweight.watermark_code_type.from_random(\n",
    "            rng, logits.shape[1]\n",
    "        )\n",
    "\n",
    "        reweighted_logits = self.reweight.reweight(watermark_code, logits)\n",
    "\n",
    "        if self.ignore_history:\n",
    "            return reweighted_logits\n",
    "        else:\n",
    "            return np.where(mask[:, None], logits, reweighted_logits)\n",
    "\n",
    "\n",
    "class WatermarkDetector:\n",
    "    def __init__(\n",
    "            self,\n",
    "            private_key: any,\n",
    "            reweight: AbstractReweight,\n",
    "            context_code_length: int,\n",
    "            vocab_size: int = 20,\n",
    "            ignore_history: bool = False\n",
    "    ):\n",
    "        self.private_key = private_key\n",
    "        self.cc_length = context_code_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.reweight = reweight\n",
    "        self.ignore_history = ignore_history\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.cc_history = set()\n",
    "\n",
    "    def get_rng_seed(self, context_code: any) -> any:\n",
    "        if not self.ignore_history:\n",
    "            self.cc_history.add(context_code)\n",
    "        import hashlib\n",
    "\n",
    "        m = hashlib.sha256()\n",
    "        m.update(context_code)\n",
    "        m.update(self.private_key)\n",
    "        full_hash = m.digest()\n",
    "        seed = int.from_bytes(full_hash, \"big\") % (2 ** 32 - 1)\n",
    "        return seed\n",
    "\n",
    "    def _get_codes(self, context):\n",
    "        batch_size = len(context)\n",
    "\n",
    "        context_codes = [\n",
    "            context[i][-self.cc_length:].tobytes() for i in range(batch_size)\n",
    "        ]\n",
    "\n",
    "        mask, seeds = zip(\n",
    "            *[\n",
    "                (context_code in self.cc_history, self.get_rng_seed(context_code))\n",
    "                for context_code in context_codes\n",
    "            ]\n",
    "        )\n",
    "        return mask, seeds\n",
    "\n",
    "    def detect(self,\n",
    "               input_ids: np.ndarray):\n",
    "        \"\"\"\n",
    "        :param input_ids: sequences after tokenization\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = []\n",
    "        for i in range(input_ids.shape[1]):\n",
    "\n",
    "            score = self.get_la_score(input_ids[:,:i], input_ids[:,i], self.vocab_size)\n",
    "            scores.append(score)\n",
    "            \n",
    "        scores = np.array(scores) \n",
    "        return np.sum(scores, axis=0)\n",
    "\n",
    "    def get_la_score(\n",
    "        self,\n",
    "        input_ids: np.ndarray,\n",
    "        labels: np.ndarray,\n",
    "        vocab_size: int,\n",
    "    ) -> np.ndarray:\n",
    "        assert \"get_la_score\" in dir(\n",
    "            self.reweight\n",
    "        ), \"Reweight does not support likelihood agnostic detection\"\n",
    "        mask, seeds = self._get_codes(input_ids)\n",
    "        rng = [\n",
    "            np.random.default_rng(seed) for seed in seeds\n",
    "        ]\n",
    "        mask = np.array(mask)\n",
    "        watermark_code = self.reweight.watermark_code_type.from_random(rng, vocab_size)\n",
    "        all_scores = self.reweight.get_la_score(watermark_code)\n",
    "        scores = all_scores[np.arange(all_scores.shape[0]), labels]\n",
    "        scores = np.logical_not(mask) * scores\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d235493-576d-4823-aa9f-b8777ee847f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = np.array([[ 4, np.nan, np.nan, 15, 20, 18],\n",
    "                     [ 5, np.nan, np.nan,  2,  0, 15],\n",
    "                     [ 5, np.nan, np.nan, 21, 10, 17],\n",
    "                     [ 6, np.nan, np.nan, 10, 15, 8],\n",
    "                     [ 6, np.nan, np.nan, 9, 25, 9]])\n",
    "logits = np.random.random((5, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fe2d96-62b2-4477-87cd-ca86144f6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_processor = WatermarkProcessor(private_key=b'private',\n",
    "                                         reweight=DeltaGumbel_Reweight(),\n",
    "                                         context_code_length=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d132d70c-bffa-4c45-be85-54ea8318db69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36316354, 0.59542443, 0.24230033, 0.63879487, 0.67896723,\n",
       "        0.82720807, 0.88676025, 0.15824899, 0.00889607, 0.72545931,\n",
       "        0.93644745, 0.44424959, 0.36290092, 0.08732449, 0.1200061 ,\n",
       "        0.34865266, 0.99849804, 0.84025134, 0.36790185, 0.53772777],\n",
       "       [0.95197296, 0.70819715, 0.07972865, 0.83036348, 0.61822959,\n",
       "        0.16988685, 0.40061496, 0.68030451, 0.41058003, 0.26533909,\n",
       "        0.86764167, 0.02757654, 0.61631643, 0.05568713, 0.02220829,\n",
       "        0.70892512, 0.95568788, 0.99658983, 0.63780764, 0.6710573 ],\n",
       "       [0.20165967, 0.39573435, 0.02946278, 0.2102426 , 0.01116232,\n",
       "        0.45755235, 0.05935861, 0.44202719, 0.24094968, 0.67877363,\n",
       "        0.73265155, 0.00550702, 0.32155552, 0.16857977, 0.09366355,\n",
       "        0.2702031 , 0.09740327, 0.90906146, 0.67867739, 0.8113312 ],\n",
       "       [0.50224427, 0.75140448, 0.14995572, 0.16796419, 0.1662573 ,\n",
       "        0.42600325, 0.34660815, 0.99811681, 0.01562505, 0.38494506,\n",
       "        0.73954064, 0.08743451, 0.93793213, 0.05554321, 0.43525386,\n",
       "        0.54099575, 0.7366107 , 0.98188437, 0.84304658, 0.75009991],\n",
       "       [0.89865442, 0.76934101, 0.13732122, 0.36864694, 0.41975405,\n",
       "        0.96000952, 0.37110408, 0.15304969, 0.79547009, 0.7678664 ,\n",
       "        0.67352438, 0.35288914, 0.45778266, 0.92908459, 0.74831306,\n",
       "        0.2297388 , 0.71331989, 0.93804148, 0.04796102, 0.99199836]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11812db0-6314-4a1b-a421-d463058d1240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf, 0.        ,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf],\n",
       "       [      -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf, 0.        ,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf],\n",
       "       [0.20165967, 0.39573435, 0.02946278, 0.2102426 , 0.01116232,\n",
       "        0.45755235, 0.05935861, 0.44202719, 0.24094968, 0.67877363,\n",
       "        0.73265155, 0.00550702, 0.32155552, 0.16857977, 0.09366355,\n",
       "        0.2702031 , 0.09740327, 0.90906146, 0.67867739, 0.8113312 ],\n",
       "       [      -inf,       -inf,       -inf,       -inf, 0.        ,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf,\n",
       "              -inf,       -inf,       -inf,       -inf,       -inf],\n",
       "       [0.89865442, 0.76934101, 0.13732122, 0.36864694, 0.41975405,\n",
       "        0.96000952, 0.37110408, 0.15304969, 0.79547009, 0.7678664 ,\n",
       "        0.67352438, 0.35288914, 0.45778266, 0.92908459, 0.74831306,\n",
       "        0.2297388 , 0.71331989, 0.93804148, 0.04796102, 0.99199836]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watermark_processor('order_agnoistic', input_id, logits, 1) # add watermark, two samples are not added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f762dd3b-ab30-476e-a9d5-b2a3e6a846aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36316354, 0.59542443, 0.24230033, 0.63879487, 0.67896723,\n",
       "        0.82720807, 0.88676025, 0.15824899, 0.00889607, 0.72545931,\n",
       "        0.93644745, 0.44424959, 0.36290092, 0.08732449, 0.1200061 ,\n",
       "        0.34865266, 0.99849804, 0.84025134, 0.36790185, 0.53772777],\n",
       "       [0.95197296, 0.70819715, 0.07972865, 0.83036348, 0.61822959,\n",
       "        0.16988685, 0.40061496, 0.68030451, 0.41058003, 0.26533909,\n",
       "        0.86764167, 0.02757654, 0.61631643, 0.05568713, 0.02220829,\n",
       "        0.70892512, 0.95568788, 0.99658983, 0.63780764, 0.6710573 ],\n",
       "       [0.20165967, 0.39573435, 0.02946278, 0.2102426 , 0.01116232,\n",
       "        0.45755235, 0.05935861, 0.44202719, 0.24094968, 0.67877363,\n",
       "        0.73265155, 0.00550702, 0.32155552, 0.16857977, 0.09366355,\n",
       "        0.2702031 , 0.09740327, 0.90906146, 0.67867739, 0.8113312 ],\n",
       "       [0.50224427, 0.75140448, 0.14995572, 0.16796419, 0.1662573 ,\n",
       "        0.42600325, 0.34660815, 0.99811681, 0.01562505, 0.38494506,\n",
       "        0.73954064, 0.08743451, 0.93793213, 0.05554321, 0.43525386,\n",
       "        0.54099575, 0.7366107 , 0.98188437, 0.84304658, 0.75009991],\n",
       "       [0.89865442, 0.76934101, 0.13732122, 0.36864694, 0.41975405,\n",
       "        0.96000952, 0.37110408, 0.15304969, 0.79547009, 0.7678664 ,\n",
       "        0.67352438, 0.35288914, 0.45778266, 0.92908459, 0.74831306,\n",
       "        0.2297388 , 0.71331989, 0.93804148, 0.04796102, 0.99199836]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watermark_processor('order_agnoistic', input_id, logits, 2) # no watermark should be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e54c83-a703-4d55-837e-2220d864d289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36316354, 0.59542443, 0.24230033, 0.63879487, 0.67896723,\n",
       "        0.82720807, 0.88676025, 0.15824899, 0.00889607, 0.72545931,\n",
       "        0.93644745, 0.44424959, 0.36290092, 0.08732449, 0.1200061 ,\n",
       "        0.34865266, 0.99849804, 0.84025134, 0.36790185, 0.53772777],\n",
       "       [0.95197296, 0.70819715, 0.07972865, 0.83036348, 0.61822959,\n",
       "        0.16988685, 0.40061496, 0.68030451, 0.41058003, 0.26533909,\n",
       "        0.86764167, 0.02757654, 0.61631643, 0.05568713, 0.02220829,\n",
       "        0.70892512, 0.95568788, 0.99658983, 0.63780764, 0.6710573 ],\n",
       "       [0.20165967, 0.39573435, 0.02946278, 0.2102426 , 0.01116232,\n",
       "        0.45755235, 0.05935861, 0.44202719, 0.24094968, 0.67877363,\n",
       "        0.73265155, 0.00550702, 0.32155552, 0.16857977, 0.09366355,\n",
       "        0.2702031 , 0.09740327, 0.90906146, 0.67867739, 0.8113312 ],\n",
       "       [0.50224427, 0.75140448, 0.14995572, 0.16796419, 0.1662573 ,\n",
       "        0.42600325, 0.34660815, 0.99811681, 0.01562505, 0.38494506,\n",
       "        0.73954064, 0.08743451, 0.93793213, 0.05554321, 0.43525386,\n",
       "        0.54099575, 0.7366107 , 0.98188437, 0.84304658, 0.75009991],\n",
       "       [0.89865442, 0.76934101, 0.13732122, 0.36864694, 0.41975405,\n",
       "        0.96000952, 0.37110408, 0.15304969, 0.79547009, 0.7678664 ,\n",
       "        0.67352438, 0.35288914, 0.45778266, 0.92908459, 0.74831306,\n",
       "        0.2297388 , 0.71331989, 0.93804148, 0.04796102, 0.99199836]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watermark_processor('order_agnoistic', input_id, logits, 3) # no watermark should be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e420e-7d59-41e8-b47b-4f6265435290",
   "metadata": {},
   "source": [
    "### Naive tokenizer construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2512b05-9df9-495b-bc70-77216a90060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 17, 2, 0, 2, 16, 13, 8, 0, 9, 2, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWYX'  # List of amino acids\n",
    "# Create a dictionary mapping each amino acid to its index\n",
    "aa_to_index = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "class AminoAcidTokenizer:\n",
    "    def __init__(self, aa_to_index):\n",
    "        self.aa_to_index = aa_to_index\n",
    "        self.index_to_aa = {idx: aa for aa, idx in aa_to_index.items()}\n",
    "        \n",
    "    def encode(self, sequence):\n",
    "        # Encode a sequence of amino acids to indices\n",
    "        return [self.aa_to_index.get(aa, self.aa_to_index.get('X')) for aa in sequence]\n",
    "        \n",
    "    def decode(self, indices):\n",
    "        # Decode a list of indices back into an amino acid sequence\n",
    "        return ''.join(self.index_to_aa.get(idx, 'X') for idx in indices)\n",
    "tokenizer = AminoAcidTokenizer(aa_to_index)\n",
    "encoded_input = tokenizer.encode(\"MVDADTQKALDFI\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b42716-8fdf-4733-9520-56e36117ae3a",
   "metadata": {},
   "source": [
    "### Read Tokenizer File to construct original tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720f1f0f-f975-4c60-8274-8e6ff13e0286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cys/miniconda3/envs/BSW/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 11, 19, 19, 25, 25, 21, 15, 8, 9, 13, 21, 11, 21, 11, 13, 21, 25, 9, 10, 8, 5, 11, 11, 25, 25, 21, 15, 15, 23, 9, 21, 15, 9, 21, 5, 5, 5, 9, 19, 5, 15, 21, 25, 19, 15, 5, 15, 21, 5, 22, 21, 11, 21, 21, 9, 13, 21, 15, 20, 5, 8, 21, 25, 11, 19, 15, 21, 5, 15, 23, 9, 21, 15, 25, 9, 15, 22, 5, 19, 9, 21, 25, 5, 25, 21, 15, 5, 19, 11, 8, 9, 11, 11, 25, 9, 25, 15, 19, 21, 25, 9, 5, 15, 25, 15, 5, 25, 15, 8, 19, 8, 21, 9, 25, 9, 25, 5, 25, 15, 5, 11, 14, 5, 21, 22, 9, 13, 22, 15, 25, 5, 11, 21, 21, 15, 15, 9, 21, 21, 25, 5, 22, 9, 19, 15, 19, 5, 5, 5, 25, 15, 5, 10, 15, 11, 9, 5, 15, 21, 9, 9, 15, 15, 25, 19, 15, 8, 5, 15, 21, 11, 15, 5, 21, 21, 25, 5, 9, 11, 11, 11, 5, 9, 15, 21, 15, 23, 15, 15, 22, 21, 5, 21, 5, 9, 25, 25, 15]\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"./tokenizer.json\")\n",
    "# generated with cmd line:\n",
    "# python3 sample_wm.py --model progen2-large --t 0.8 --p 0.9 --max-length 100 --num-samples 1 --context \"2\" --rng-seed 0\n",
    "encoded_input = tokenizer.encode(\"GGPPVVRLDEIRGRGIRVEFDAGGVVRLLTERLERAAAEPALRVPLALRASRGRREIRLQADRVGPLRALTERLVELSAPERVAVRLAPGDEGGVEVLPRVEALVLAVLDPDREVEVAVLAGKARSEISLVAGRRLLERRVASEPLPAAAVLAFLGEALREELLVPLDALRGLARRVAEGGGAELRLTLLSRARAEVVL\")\n",
    "# encoded_input = tokenizer.encode(\"2GGPPVVRLD\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e08e8ae8-5df8-443c-be3d-ae24bc87fa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c334378-0f72-44d8-aba5-a6e5986f3db0",
   "metadata": {},
   "source": [
    "### Detection with Private Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ce280dc-fa05-4fa9-95a9-56473b9de64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a98a60e-98fc-426b-bd7c-6d289cabe5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = np.array(encoded_input).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ab91c4b-6a69-4b10-b40d-3e53c8dc8bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63.62662829])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.detect(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85acab9f-754e-4ded-8f14-5f9e7599f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.log(2) - (1/30) # theoretically maximum expectation score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c9c3e-e841-4f56-972a-ff6c5e636735",
   "metadata": {},
   "source": [
    "### Without watermark in the model, we can not detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbb46a61-177a-4ddd-b0ca-8328921a7c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 23, 5, 9, 9, 9, 23, 8, 5, 5, 15, 9, 5, 8, 22, 15, 9, 5, 5, 25, 21, 14, 5, 9, 8, 13, 8, 15, 9, 11, 14, 11, 15, 5, 5, 15, 15, 5, 9, 13, 9, 19, 10, 11, 22, 9, 23, 5, 15, 21, 9, 15, 11, 23, 15, 16, 11, 9, 5, 21, 22, 25, 5, 15, 22, 22, 25, 23, 11, 12, 5, 23, 14, 5, 25, 22, 11, 15, 14, 5, 15, 23, 23, 5, 25, 22, 20, 5, 9, 5, 11, 5, 22, 13, 28, 15, 19, 14, 20]\n"
     ]
    }
   ],
   "source": [
    "# generated with cmd line:\n",
    "# python3 sample.py --model progen2-large --t 0.8 --p 0.9 --max-length 100 --num-samples 1 --context \"2\" --rng-seed 0\n",
    "encoded_input = tokenizer.encode(\"DTAEEETDAALEADSLEAAVRKAEDIDLEGKGLAALLAEIEPFGSETALRELGTLMGEARSVALSSVTGHATKAVSGLKALTTAVSQAEAGASIYLPKQ\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c30c9a98-9e34-452f-b27d-79bcb0ab8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)\n",
    "input_ids = np.array(encoded_input).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd4cf579-92b1-422e-b361-2b58fbee41a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-26.23357289])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.detect(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff807947-4db8-434d-b253-9321992591fa",
   "metadata": {},
   "source": [
    "### Without Correct Key, Score Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9547176-1b18-4028-8b3d-bd415e38efb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-69.73725497])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated with cmd line:\n",
    "# python3 sample_wm.py --model progen2-large --t 0.8 --p 0.9 --max-length 100 --num-samples 1 --context \"2\" --rng-seed 0\n",
    "encoded_input = tokenizer.encode(\"GGPPVVRLDEIRGRGIRVEFDAGGVVRLLTERLERAAAEPALRVPLALRASRGRREIRLQADRVGPLRALTERLVELSAPERVAVRLAPGDEGGVEVLPRVEALVLAVLDPDREVEVAVLAGKARSEISLVAGRRLLERRVASEPLPAAAVLAFLGEALREELLVPLDALRGLARRVAEGGGAELRLTLLSRARAEVVL\")\n",
    "input_ids = np.array(encoded_input).reshape(1,-1)\n",
    "detector = WatermarkDetector(b\"private keey\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)\n",
    "detector.detect(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f2b49-f35e-42eb-b818-e71884eb90f8",
   "metadata": {},
   "source": [
    "### Watermark is Relatively Robust to Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84847677-ffc8-4cbd-9d44-96bd790836d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.63254586])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"./tokenizer.json\")\n",
    "# select the head of the protein\n",
    "encoded_input = tokenizer.encode(\"GGPPVVRLDEIRGRGIRVEFDAGGVVRLLTERLERAAAEPALRVPLAL\")\n",
    "input_ids = np.array(encoded_input).reshape(1,-1)\n",
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)\n",
    "detector.detect(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66d383a8-d142-487f-b6a1-2ab4461c12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 11, 19, 19, 25, 25, 21, 15, 8, 9, 13, 21, 11, 21, 11, 13, 21, 25, 9, 10, 8, 11, 11, 11, 25, 25, 21, 15, 15, 23, 9, 21, 15, 9, 21, 11, 11, 11, 9, 19, 11, 15, 21, 25, 19, 15, 11, 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.64354916])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify the sequence by changing A to G\n",
    "encoded_input = tokenizer.encode(\"GGPPVVRLDEIRGRGIRVEFDGGGVVRLLTERLERGGGEPGLRVPLGL\")\n",
    "print(encoded_input)\n",
    "input_ids = np.array(encoded_input).reshape(1,-1)\n",
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)\n",
    "detector.detect(input_ids) # we still have some watermark in it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473e53e-a7f1-4270-8f13-666e9a06b44e",
   "metadata": {},
   "source": [
    "### Detect multiple sequences at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa05aa5-e3f5-4fab-9a95-71ef331720c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.64354916, 0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = WatermarkDetector(b\"private key\",\n",
    "                             DeltaGumbel_Reweight(),\n",
    "                             context_code_length=5,\n",
    "                             vocab_size=30)\n",
    "detector.detect(np.concatenate([input_ids, input_ids])) # we still have some watermark in it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e045b4-5470-4f03-901b-fd2022ba7c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
